{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity 20.2: Using Python for Spam Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Outcome Addressed:\n",
    "\n",
    "- 6. Implement spam detection using Python.\n",
    "\n",
    "## Activity Overview\n",
    "\n",
    "In this activity, you will apply the Naïve Bayes theorem to a database that contains spam emails.\n",
    "Naïve Bayes is a classification technique based on Bayes theorem with an assumption of independence among predictors. \n",
    "\n",
    "Bayes theorem is stated mathematically as the following equation:\n",
    "\n",
    "$$P(A | B) = \\frac{P(B|A)P(A)}{P(B)},$$\n",
    "\n",
    "where\n",
    "\n",
    " - $P(A| B)$ is a conditional probability: the likelihood of event $A$ occurring given that $B$ is true.\n",
    " - $P(B|A)$ is also a conditional probability: the likelihood of event $B$ occurring given that $A$ is true.\n",
    " - $P(A)$ and $P(B)$ are the probabilities of observing events $A$ and $B$.\n",
    "\n",
    "In simple terms, a Naïve Bayes classifier assumes that the presence of a particular feature in a *class* is unrelated to the presence of any other feature. \n",
    "\n",
    "For example, a fruit may be considered to be an apple if it is red, round, and about three inches in diameter. Even if these features depend on each other or upon the existence of the other features, these properties independently contribute to the probability that this fruit is an apple. That is why it is known as ‘Naïve’.\n",
    "\n",
    "This activity is designed to help you apply the machine learning algorithms that you have learned using *packages* in Python. Python concepts, instructions, and the starter code are embedded within this Jupyter Notebook to help guide you as you progress through the activity. Remember to run the code of each code cell prior to your submission. Upon completing the activity, you are encouraged to compare your work against the solution file to perform a self-assessment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index:\n",
    "\n",
    "- [Part 1 - Importing the Dataset and Exploratory Data Analysis (EDA)](#part1)\n",
    "- [Part 2 - Shuffling  and Splitting the Emails](#part2)\n",
    "- [Part 3 - Building a Simple Naïve Bayes Classifier From Scratch](#part3)\n",
    "- [Part 4 - Explaining the Code Given in Part 3](#part4)\n",
    "- [Part 5 - Train the Classifier `train`](#part5)\n",
    "- [Part 6 - Explore the Performance of `train` Classifier ](#part6)\n",
    "- [Part 7 - Training the `train2` Classifier ](#part7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## The Naïve Bayes Algorithm\n",
    "\n",
    "You have now learned about the **Naïve Bayes algorithm** for classification. \n",
    "\n",
    "The pseudo-algorithm for Naïve Bayes can be summarized as follows: \n",
    "1. Load the training and test data.\n",
    "2. Shuffle the messages and split them.\n",
    "3. Build a simple Naïve Bayes classifier from scratch.\n",
    "4. Train the classifier and explore the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Build a Naïve Bayes Spam Filter\n",
    "\n",
    "For this exercise, you will use the [“SMSSpamCollection”](https://archive.ics.uci.edu/ml/machine-learning-databases/00228/) dataset  to build a Naïve Bayes spam filter by going through the following steps:\n",
    "\n",
    "1. Load the data file.\n",
    "2. Shuffle the messages and split them into a training set (2,500 emails), a validation set (1,000 messages), and a test set (all remaining messages).\n",
    "3. Build a simple Naïve Bayes classifier.\n",
    "4. Explain the code given in Part 3.\n",
    "5. Use your training set to train the ‘train’ classifier. Note that the interfaces of the classifiers require you to pass the non-spam and spam emails separately.\n",
    "6. Using the validation set, explore how the classifier performs.\n",
    "7. Define a second classifier and compare its performance with the one defined in Part 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part1'></a>\n",
    "\n",
    "### Part 1: Importing the Dataset and  Exploratory Data Analysis (EDA)\n",
    "\n",
    "Begin by using `pandas` to import the dataset. To do so, import `pandas` first and then read the file using the `.read_csv` *function* by passing the name of the dataset that you want to read as a *string*.\n",
    "\n",
    "Notice that because the rows in the dataset are separated using a `\\t`, the type of delimiter is specified in the `.read_csv()` *function*; the default value is `,`. Additionally, the list of column names to use is specified (`\"label\"` and `\"emails\"`).\n",
    "\n",
    "Complete the code cell below by adding the name of the dataset inside `.read_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5w/7z6194rx60v3sjqsxz6x35dm0000gn/T/ipykernel_43723/2598343455.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0memails\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"email\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "emails = pd.read_csv('', sep = '\\t', names = [\"label\", \"email\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before performing any algorithm on the *dataframe*, it is always good practice to perform exploratory data analysis.\n",
    "\n",
    "Begin by visualizing the first ten rows of the `df` *dataframe* using the `head()` *function*. By default, *`head()`* displays the first five rows of a *dataframe*.\n",
    "\n",
    "Complete the code cell below by passing the desired number of rows to the `head()` *function* as an *integer*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Next, you can retrieve some more information about your *dataframe* by using the `shape` and `columns` *methods* and the `describe()` *function*.\n",
    "\n",
    "Here's a brief description of what each of the above *functions* does:\n",
    "- `shape`: returns a *tuple* representing the dimensionality of the *dataframe*.\n",
    "- `columns`: returns the column labels of the *dataframe*.\n",
    "- `describe()`: returns summary statistics of the columns in the *dataframe* provided, such as mean, count, standard deviation, etc.\n",
    "\n",
    "Run the cells below to review the information about the *dataframe*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emails' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5w/7z6194rx60v3sjqsxz6x35dm0000gn/T/ipykernel_43723/498990545.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'emails' is not defined"
     ]
    }
   ],
   "source": [
    "emails.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emails' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5w/7z6194rx60v3sjqsxz6x35dm0000gn/T/ipykernel_43723/98439225.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'emails' is not defined"
     ]
    }
   ],
   "source": [
    "emails.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emails' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5w/7z6194rx60v3sjqsxz6x35dm0000gn/T/ipykernel_43723/2466478181.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'emails' is not defined"
     ]
    }
   ],
   "source": [
    "emails.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part2'></a>\n",
    "\n",
    "### Part 2: Shuffling  and Splitting the Text Messages\n",
    "\n",
    "In the second part of this activity, you will shuffle the emails and split them into a training set (2,500 messages), a validation set (1,000 messages), and a test set (all remaining messages).\n",
    "\n",
    "Begin by shuffling the messages. This can be done using the `sample` *function* from the `pandas` *library*.\n",
    "\n",
    "Complete the code cell below by applying the `sample()` *function* to the *dataframe* emails. Set the `frac = 1` *argument* and `random_state = 0`. `frac` denotes the proportion of the *dataframe* to sample, and `random_state` is a random seed that ensures reproducibility of your results. \n",
    "\n",
    "Next, reset the *index* of `emails` to align with the shuffled emails by using the `reset_index` *function* with the appropriate *argument*. \n",
    "\n",
    "Here's a link for you where you can find the documentation about the [`reset_index()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reset_index.html) *function*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below to visualize the updated *dataframe*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you need to split the emails into a training set (the first 2,500 emails in the *dataframe*), a validation set (the next 1,000 emails), and a testing set (the remaining emails). These three sets will be defined as `trainingMsgs`, `valMsgs`, and `testingMsgs`.\n",
    "\n",
    "In the code cell below, the messages and their correspoding labels are defined. Next, you will split the messages into the required sets according to the instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = list(emails.email) \n",
    "lbls =list(emails.label) \n",
    "trainingEmail = email[:2500] \n",
    "valEmail = email[2500:3500] \n",
    "testingEmail = email[3500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the syntax used above, complete the cell below to split the labels into a training set, a validation set, and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traininglbls =\n",
    "vallbls = \n",
    "testinglbls = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part3'></a>\n",
    "\n",
    "### Part 3: Building a Simple Naïve Bayes Classifier From Scratch\n",
    "\n",
    "While Python’s SciKit-learn *library* has a [Naïve Bayes classifier](https://scikit-learn.org/stable/modules/naive_bayes.html), it works with continuous probability distributions and assumes numerical features. \n",
    "\n",
    "Here, you will instead build a simple Naïve Bayes classifier from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class NaiveBayesForSpam:\n",
    "    def train (self, nonSPamMessages, spamMessages):\n",
    "        self.words = set (' '.join (nonSPamMessages + spamMessages).split())\n",
    "        self.priors = np.zeros (2)\n",
    "        self.priors[0] = float (len (nonSPamMessages)) / (len (nonSPamMessages) + len (spamMessages))\n",
    "        self.priors[1] = 1.0 - self.priors[0]\n",
    "        self.likelihoods = []\n",
    "        for i, w in enumerate (self.words):\n",
    "            prob1 = (1.0 + len ([m for m in nonSPamMessages if w in m])) / len (nonSPamMessages)\n",
    "            prob2 = (1.0 + len ([m for m in spamMessages if w in m])) / len (spamMessages)\n",
    "            self.likelihoods.append ([min (prob1, 0.95), min (prob2, 0.95)])\n",
    "        self.likelihoods = np.array (self.likelihoods).T\n",
    "        \n",
    "    def predict (self, message):\n",
    "        posteriors = np.copy (self.priors)\n",
    "        for i, w in enumerate (self.words):\n",
    "            if w in message.lower():  # convert to lower-case\n",
    "                posteriors *= self.likelihoods[:,i]\n",
    "            else:                                   \n",
    "                posteriors *= np.ones (2) - self.likelihoods[:,i]\n",
    "            posteriors = posteriors / np.linalg.norm (posteriors)  # normalize\n",
    "        if posteriors[0] > 0.5:\n",
    "            return ['ham', posteriors[0]]\n",
    "        return ['spam', posteriors[1]]    \n",
    "\n",
    "    def score (self, messages, labels):\n",
    "        confusion = np.zeros(4).reshape (2,2)\n",
    "        for m, l in zip (messages, labels):\n",
    "            if self.predict(m)[0] == 'ham' and l == 'ham':\n",
    "                confusion[0,0] += 1\n",
    "            elif self.predict(m)[0] == 'ham' and l == 'spam':\n",
    "                confusion[0,1] += 1\n",
    "            elif self.predict(m)[0] == 'spam' and l == 'ham':\n",
    "                confusion[1,0] += 1\n",
    "            elif self.predict(m)[0] == 'spam' and l == 'spam':\n",
    "                confusion[1,1] += 1\n",
    "        return (confusion[0,0] + confusion[1,1]) / float (confusion.sum()), confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part4'></a>\n",
    "\n",
    "### Part 4: Explaining the Code Provided in Part 3\n",
    "\n",
    "Before explaining the code that was provided in Part 3, it is important to have some level of intuition as to what a spam email message might look like. Usually they have words designed to catch your eye and, in some sense, to tempt you to open them. Also, spam emails tend to have words written in all capital letters and use a lot of exclamation marks.\n",
    "\n",
    "The `train` *function* calculates and stores the prior probabilities and likelihoods based on the training dataset. In Naïve Bayes, this is all the training phase does. \n",
    "\n",
    "The `predict` *function* repeatedly applies the Naïve Bayes theorem to every word in the constructed *dictionary* and, based on the posterior probability, it classifies each email as `spam` or `non-spam`. The `score` *function* calls `predict` for multiple emails and compares the outcomes with the supplied `ground truth` labels, thus evaluating the classifier. It also computes and returns a confusion matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part5'></a>\n",
    "\n",
    "### Part 5: Training the `train`  Classifier\n",
    "\n",
    "Looking at the definition of the `train` *function* in Part 2, you can see that the training *functions* require the `non-spam` and `spam` emails to be passed on separately.\n",
    "\n",
    "The `non-spam` emails can be passed using the code given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonSpamEmails = [m for (m, l) in zip(trainingEmail, traininglbls) if 'ham' in l]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the cell below to pass the spam emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spamEmails = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to see how many `non-spam` and `spam` emails you have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(nonSpamEmails))\n",
    "print(len(spamEmails))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Their sum equals 2,500 as expected. \n",
    "\n",
    "Next, you need to create the classifier for your analysis using the `NaiveBayesForSpam`*function*. \n",
    "\n",
    "After that, you will train `non-spammsgs` and `spammsgs` using the `train` *function*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = NaiveBayesForSpam()\n",
    "clf.train(nonSPamEmails, spamEmails)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part6'></a>\n",
    "\n",
    "### Part 6: Exploring the Performance of the `train` Classifier\n",
    "\n",
    "You can explore the performance of the two classifiers on the *validation set* by using the `.score()` *function*.\n",
    "\n",
    "Complete the code cell below to compute the score and the confusion matrix for this case.\n",
    "\n",
    "\n",
    "**IMPORTANT NOTE: Results in the following sections will change. This is expected and due to the random shuffling. The results will be different for each shuffling. To ensure reproducible results, define `random_state` in the `sample` *method* when shuffling the data in [Part 2: Shuffling and Splitting the Text Messages](#part2).**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score, confusion = clf.score (valEmail, vallbls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cells below to print the score and the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The overall performance is:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The confusion matrix is:\\n\", confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your data is not equally divided into the two *classes*. As a baseline, let’s see what the success rate would be if you always guessed non-spam.\n",
    "\n",
    "Run the code cell below to *print* the new score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('new_score', len([1 for l in vallbls if 'ham' in l]) / float (len ( vallbls)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the baseline score to the performance on the validation set. Which is better?\n",
    "\n",
    "You can also calculate the sample error by calculating the score and the confusion matrix on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: this cell may take a LONG time to run!\n",
    "score, confusion = clf.score (trainingEmail, traininglbls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The overall performance is:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The confusion matrix is:\\n\", confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to top](#Index:) \n",
    "\n",
    "<a id='part7'></a>\n",
    "\n",
    "### Part 7: Training the `train2` Classifier\n",
    "\n",
    "In this section, you will define a second classifier, `train2`, and compare its performance to the `train` classifier defined above.\n",
    "\n",
    "The `train2` classifier is defined in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesForSpam:\n",
    "    def train2 ( self , nonSpamMessages , spamMessages) :\n",
    "            self.words = set (' '.join (nonSpamMessages + spamMessages).split())\n",
    "            self.priors = np. zeros (2)\n",
    "            self.priors [0] = float (len (nonSpamMessages)) / (len (nonSpamMessages) +len( spamMessages ) )\n",
    "            self.priors [1] = 1.0 - self . priors [0] \n",
    "            self.likelihoods = []\n",
    "            spamkeywords = [ ]\n",
    "            for i, w in enumerate (self.words):\n",
    "                prob1 = (1.0 + len ([m for m in nonSpamMessages if w in m])) /len ( nonSpamMessages )\n",
    "                prob2 = (1.0 + len ([m for m in spamMessages if w in m])) /len ( spamMessages ) \n",
    "                if prob1 * 20 < prob2:\n",
    "                    self.likelihoods.append([min (prob1 , 0.95) , min (prob2 , 0.95) ])\n",
    "                    spamkeywords . append (w) \n",
    "            self.words = spamkeywords\n",
    "            self.likelihoods = np.array (self.likelihoods).T \n",
    "            \n",
    "    def predict (self, message):\n",
    "        posteriors = np.copy (self.priors)\n",
    "        for i, w in enumerate (self.words):\n",
    "            if w in message.lower():  # convert to lower-case\n",
    "                posteriors *= self.likelihoods[:,i]\n",
    "            else:                                   \n",
    "                posteriors *= np.ones (2) - self.likelihoods[:,i]\n",
    "            posteriors = posteriors / np.linalg.norm (posteriors)  # normalise\n",
    "        if posteriors[0] > 0.5:\n",
    "            return ['ham', posteriors[0]]\n",
    "        return ['spam', posteriors[1]]    \n",
    "\n",
    "    def score (self, messages, labels):\n",
    "        confusion = np.zeros(4).reshape (2,2)\n",
    "        for m, l in zip (messages, labels):\n",
    "            if self.predict(m)[0] == 'ham' and l == 'ham':\n",
    "                confusion[0,0] += 1\n",
    "            elif self.predict(m)[0] == 'ham' and l == 'spam':\n",
    "                confusion[0,1] += 1\n",
    "            elif self.predict(m)[0] == 'spam' and l == 'ham':\n",
    "                confusion[1,0] += 1\n",
    "            elif self.predict(m)[0] == 'spam' and l == 'spam':\n",
    "                confusion[1,1] += 1\n",
    "        return (confusion[0,0] + confusion[1,1]) / float (confusion.sum()), confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you need to update the classifier for your analysis using the `NaiveBayesForSpam` *function*. Complete the cell below to create the `clf` classifier.\n",
    "\n",
    "Next, train `non-spammsgs` and `spammsgs` using the `train2` *function*. \n",
    "\n",
    "*HINT:* For this last part, look at the definition of the `train2` *function*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = \n",
    "#train using the new classifier\n",
    "clf.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-compute the score and the confusion matrix on the validation set using the updated classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Again, this cell may take a long time to run!\n",
    "score_2, confusion_2 = clf.score(valEmails, vallbls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cells below to get the updated values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The overall performance is: \", score_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The confusion matrix is:\\n\", confusion_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Question 1: How does the performance of the two classifiers compare?**\n",
    "\n",
    "- **Question 2: What do the `train` and `train2` classifiers do, and what is the difference between them?**\n",
    "\n",
    "\n",
    "You can double-click this cell to write your answers.\n",
    "\n",
    "**YOUR ANSWERS**\n",
    "\n",
    "Question 1: \n",
    "\n",
    "Question 2: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Now you know how to implement Naïve Bayes for detecting spam emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
